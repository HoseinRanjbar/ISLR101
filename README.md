<h1 align="center">ISLR101: Iranian Word-Level Sign Language Recognition Dataset</h1>

<p align="center">
  <b>
    <span style="color:blue"> Hossein Ranjbar<sup>1</sup>, Alireza Taheri<sup>2</sup></span>
  </b>
</p>

<p align="center">
  <sup>1</sup> <span style="color:darkgreen">Department of Computational Linguistics, University of Zurich, Zurich, Switzerland</span> <br>
  <sup>2</sup> <span style="color:darkgreen">Department of Mechanical Engineering, Sharif University of Technology, Tehran, Iran</span>
</p>


---

## Introduction

we introduce ISLR101 dataset, the first publicly available
Iranian Sign Language dataset for isolated sign language recognition. This comprehensive
dataset includes 4,614 videos covering 101 distinct signs, recorded from 10 different signers,
along with pose information extracted using OpenPose. We establish visual appearance-based
and skeleton-based frameworks as baseline models, thoroughly training and evaluating them
on ISLR101 to demonstrate their effectiveness.


<img src="https://github.com/user-attachments/assets/a919d4c1-b0c2-4fac-9b94-3cbbf26343f8" alt="1" height="500">


This repository provides a PyTorch-based implementation of **Video-based Emotion Recognition**( MobileNet-V2 + Local Transformer). 
